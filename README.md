# Context is Key: A Benchmark for Forecasting with Essential Textual Information

ğŸ“„ [Paper (ICML 2025)](https://arxiv.org/abs/2410.18959) -
ğŸŒ [Website](https://servicenow.github.io/context-is-key-forecasting) -
âœ‰ï¸ [Contact](mailto:arjun.ashok@servicenow.com,andrew.williams1@servicenow.com,alexandre.drouin@servicenow.com) -
ğŸŒŸ [Contributors](#contributors) -
ğŸ“ [Citation](#citing-this-work) -
ğŸ“¦ [ICML 2025 Release](https://github.com/ServiceNow/context-is-key-forecasting/tree/v1.0.0) -
ğŸ“Š [Official Results](#official-results) -
ğŸ¤— [Hugging Face Dataset](https://huggingface.co/datasets/ServiceNow/context-is-key)

![poster](https://github.com/user-attachments/assets/523ae60a-6c3d-42bf-80b8-83e23d8e7ab0)

## Overview of code

* **Baselines:** All baseline code can be found [here](./cik_benchmark/baselines).
* **Tasks:** All baseline code can be found [here](./cik_benchmark/tasks).
* **Metrics:** All metric-related code can be found [here](./cik_benchmark/metrics).
* **Experiments:** Code used to run the experiments can be found [here](./experiments).


## Official results

Here are the updated aggregated benchmark results (equivalent to Table 1 in the paper).
The full experimental results can also be found [here](./results/results_complete.csv).

This table holds for the version of the benchmark as of July 11th, 2025.
See the [CHANGELOG](./CHANGELOG) for how the benchmark was updated since the ICML 2025 release.

|                                         | Average RCPRS   | Intemporal Information   | Historical Information   | Future Information   | Covariate Information   | Causal Information   |
|:----------------------------------------|:----------------|:-------------------------|:-------------------------|:---------------------|:------------------------|:---------------------|
| Direct Prompt - Llama-3.1-405B-Instruct | 0.143 Â± 0.006   | 0.174 Â± 0.010            | 0.146 Â± 0.001            | 0.075 Â± 0.005        | 0.144 Â± 0.008           | 0.303 Â± 0.037        |
| Direct Prompt - Llama-3-70B-Instruct    | 0.286 Â± 0.004   | 0.336 Â± 0.006            | 0.180 Â± 0.003            | 0.193 Â± 0.006        | 0.228 Â± 0.004           | 0.629 Â± 0.019        |
| Direct Prompt - Mixtral-8x7B-Instruct   | 0.519 Â± 0.009   | 0.723 Â± 0.014            | 0.236 Â± 0.002            | 0.241 Â± 0.001        | 0.353 Â± 0.004           | 0.850 Â± 0.012        |
| Direct Prompt - Qwen-2.5-7B-Instruct    | 0.290 Â± 0.003   | 0.290 Â± 0.004            | 0.176 Â± 0.003            | 0.287 Â± 0.007        | 0.240 Â± 0.002           | 0.524 Â± 0.003        |
| Direct Prompt - Qwen-2.5-0.5B-Instruct  | 0.463 Â± 0.018   | 0.609 Â± 0.028            | 0.165 Â± 0.004            | 0.218 Â± 0.012        | 0.476 Â± 0.022           | 0.428 Â± 0.006        |
| Direct Prompt - GPT-4o                  | 0.191 Â± 0.004   | 0.218 Â± 0.007            | 0.118 Â± 0.001            | 0.121 Â± 0.001        | 0.143 Â± 0.003           | 0.363 Â± 0.011        |
| Direct Prompt - GPT-4o-mini             | 0.354 Â± 0.004   | 0.475 Â± 0.007            | 0.139 Â± 0.002            | 0.143 Â± 0.002        | 0.341 Â± 0.004           | 0.645 Â± 0.011        |
| LLMP - Llama3-70B-Instruct              | 0.540 Â± 0.013   | 0.438 Â± 0.018            | 0.516 Â± 0.029            | 0.847 Â± 0.024        | 0.547 Â± 0.016           | 0.396 Â± 0.028        |
| LLMP - Llama3-70B                       | 0.237 Â± 0.006   | 0.212 Â± 0.005            | 0.121 Â± 0.008            | 0.299 Â± 0.017        | 0.194 Â± 0.004           | 0.365 Â± 0.011        |
| LLMP - Mixtral-8x7B-Instruct            | 0.265 Â± 0.004   | 0.242 Â± 0.007            | 0.173 Â± 0.004            | 0.324 Â± 0.005        | 0.219 Â± 0.005           | 0.440 Â± 0.007        |
| LLMP - Mixtral-8x7B                     | 0.264 Â± 0.008   | 0.250 Â± 0.008            | 0.119 Â± 0.003            | 0.310 Â± 0.019        | 0.231 Â± 0.006           | 0.466 Â± 0.011        |
| LLMP - Qwen-2.5-7B-Instruct             | 1.974 Â± 0.019   | 2.509 Â± 0.030            | 2.857 Â± 0.056            | 1.653 Â± 0.008        | 1.702 Â± 0.023           | 1.333 Â± 0.080        |
| LLMP - Qwen-2.5-7B                      | 0.910 Â± 0.034   | 1.149 Â± 0.043            | 1.002 Â± 0.053            | 0.601 Â± 0.071        | 0.640 Â± 0.044           | 0.929 Â± 0.016        |
| LLMP - Qwen-2.5-0.5B-Instruct           | 1.937 Â± 0.011   | 2.444 Â± 0.017            | 1.960 Â± 0.063            | 1.443 Â± 0.010        | 1.805 Â± 0.012           | 1.201 Â± 0.017        |
| LLMP - Qwen-2.5-0.5B                    | 1.995 Â± 0.011   | 2.546 Â± 0.018            | 2.082 Â± 0.052            | 1.579 Â± 0.015        | 1.821 Â± 0.013           | 1.225 Â± 0.013        |
| UniTime                                 | 0.370 Â± 0.001   | 0.457 Â± 0.002            | 0.155 Â± 0.000            | 0.194 Â± 0.003        | 0.395 Â± 0.001           | 0.423 Â± 0.001        |
| Time-LLM (ETTh1)                        | 0.475 Â± 0.001   | 0.517 Â± 0.002            | 0.183 Â± 0.000            | 0.403 Â± 0.002        | 0.441 Â± 0.001           | 0.481 Â± 0.002        |
| Lag-Llama                               | 0.327 Â± 0.004   | 0.330 Â± 0.005            | 0.167 Â± 0.005            | 0.293 Â± 0.008        | 0.294 Â± 0.004           | 0.494 Â± 0.014        |
| Chronos-Large                           | 0.326 Â± 0.001   | 0.314 Â± 0.002            | 0.179 Â± 0.003            | 0.379 Â± 0.003        | 0.255 Â± 0.002           | 0.460 Â± 0.004        |
| TimeGEN                                 | 0.353 Â± 0.000   | 0.332 Â± 0.000            | 0.177 Â± 0.000            | 0.405 Â± 0.000        | 0.292 Â± 0.000           | 0.474 Â± 0.000        |
| Moirai-Large                            | 0.520 Â± 0.006   | 0.596 Â± 0.009            | 0.140 Â± 0.001            | 0.431 Â± 0.002        | 0.499 Â± 0.007           | 0.438 Â± 0.011        |
| ARIMA                                   | 0.475 Â± 0.006   | 0.557 Â± 0.009            | 0.200 Â± 0.007            | 0.350 Â± 0.003        | 0.375 Â± 0.006           | 0.440 Â± 0.011        |
| ETS                                     | 0.530 Â± 0.009   | 0.639 Â± 0.014            | 0.362 Â± 0.014            | 0.315 Â± 0.006        | 0.402 Â± 0.010           | 0.507 Â± 0.017        |
| Exponential Smoothing                   | 0.605 Â± 0.013   | 0.703 Â± 0.020            | 0.493 Â± 0.016            | 0.397 Â± 0.006        | 0.480 Â± 0.015           | 0.828 Â± 0.060        |

## Setting environment variables

Here is a list of all environment variables which the Context-is-Key benchmark will access:

| Variable Name               | Description                                                                                     | Default Value                        |
|-----------------------------|-------------------------------------------------------------------------------------------------|--------------------------------------|
| **CIK_MODEL_STORE**         | Folder to store model weights for the baselines.                                                | `./models`                           |
| **CIK_DATA_STORE**          | Folder to store downloaded datasets.                                                            | `./data`                     |
| **CIK_DOMINICK_STORE**      | Folder to store the Dominick dataset for specific tasks.                                        | `CIK_DATA_STORE + /dominicks`        |
| **CIK_TRAFFIC_DATA_STORE**  | Folder to store the Traffic dataset for specific tasks.                                         | `CIK_DATA_STORE + /traffic_data`     |
| **HF_HOME**                 | Cache location for downloading datasets from Hugging Face.                                      | `CIK_DATA_STORE + /hf_cache`         |
| **CIK_RESULT_CACHE**        | Folder to store the output of baselines to avoid recomputation.                                 | `./inference_cache`                  |
| **CIK_METRIC_SCALING_CACHE**| Folder to store scaling factors for each task to avoid recomputation.                           | `./metric_scaling_cache`             |
| **CIK_METRIC_COMPUTE_VARIANCE** | If set, computes an estimate of the variance of the metric.                              | Only compute metric itself by default|
| **CIK_OPENAI_USE_AZURE**    | If set to "True", use Azure client instead of OpenAI client for baselines using OpenAI models.  | `False`                              |
| **CIK_OPENAI_API_KEY**      | API key for accessing OpenAI models.                                    | None (Required for baseline)         |
| **CIK_OPENAI_API_VERSION**  | API version for OpenAI models when using the Azure client.                                     | None                                 |
| **CIK_OPENAI_AZURE_ENDPOINT** | Azure endpoint for calling OpenAI models.                                                    | None                                 |
| **CIK_LLAMA31_405B_URL**    | API URL for the Llama-3.1-405b baseline.                                | None (Required for baseline)         |
| **CIK_LLAMA31_405B_API_KEY**| API key for the Llama-3.1-405b API.                                     | None (Required for baseline)         |
| **CIK_NIXTLA_BASE_URL**     | Azure API URL for the Nixtla TimeGEN baseline.                             | None (Required for baseline)         |
| **CIK_NIXTLA_API_KEY**          | Azure API key for the Nixtla TimeGEN baseline.                          | None (Required for baseline)         |

## ğŸŒŸ Contributors

[![CiK contributors](https://contrib.rocks/image?repo=ServiceNow/context-is-key-forecasting&max=2000)](https://github.com/ServiceNow/context-is-key-forecasting/graphs/contributors)

## Citing this work

Please cite the following paper:
```
@inproceedings{
williams2025context,
title={Context is Key: A Benchmark for Forecasting with Essential Textual Information},
author={Andrew Robert Williams and Arjun Ashok and {\'E}tienne Marcotte and Valentina Zantedeschi and Jithendaraa Subramanian and Roland Riachi and James Requeima and Alexandre Lacoste and Irina Rish and Nicolas Chapados and Alexandre Drouin},
booktitle={Forty-second International Conference on Machine Learning},
year={2025},
url={https://openreview.net/forum?id=ih2WuBT1Fn}
}
```
